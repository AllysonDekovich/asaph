#!/usr/bin/env python3
"""
Copyright 2018 Ronald J. Nowling

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
"""

import argparse
from collections import defaultdict
import os
import sys

import joblib
import matplotlib
matplotlib.use("PDF")
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import scipy.stats as stats

from asaph.feature_extraction import FeatureStringsExtractor
from asaph.newioutils import deserialize
from asaph.newioutils import MODEL_FLNAME
from asaph.newioutils import PROJECTION_KEY
from asaph.newioutils import PROJECT_SUMMARY_FLNAME
from asaph.vcf import filter_invariants
from asaph.vcf import VCFStreamer

ALPHA = 0.01

def read_snp_table(flname, component, chromosome):
    with open(flname) as fl:
        df = pd.read_csv(fl, delim_whitespace=True)
        df["chrom"] = df["chrom"].astype(str)
        mask = (df["chrom"] == chromosome) & (df["component"] == component)

        df = df[mask]
        df = df.sort_values(by="pos")
        
    return df

def mark_significant_snps(df, threshold=None):
    if threshold is None:
        threshold = ALPHA / len(df)

    df["is_significant"] = 0.0
    mask = df["pvalue"] < threshold
    df.loc[mask, "is_significant"] = 1.0    

    return df

def find_inversion_boundaries(df, n_windows, threshold=None):
    min_pos = min(df["pos"])
    max_pos = max(df["pos"])
    windows = np.linspace(min_pos, max_pos, num=n_windows)
    left_boundary = None
    right_boundary = None
    if threshold is None:
        threshold = 0.0001 / len(windows)

    # expected probability of a SNP being
    # significant assuming uniform distribution
    n_sig_snps = len(df[df["is_significant"] == 1])
    exp_prob = n_sig_snps / len(df)

    n_sig_wins = 0
    for i in range(n_windows - 1):
        mask = (df["pos"] >= windows[i]) & (df["pos"] < windows[i+1])
        df_window = df[mask]

        # number of trials (SNPs per window)
        win_snps = len(df_window)
        
        # number of successes (sig SNPs per window)
        win_sig_snps = len(df_window[df_window["is_significant"] == 1])
        
        #if len(sign_snp_marks) >= 2 and np.mean(sign_snp_marks) != 0.0:
        #    _, win_pvalue = stats.ttest_1samp(sign_snp_marks, 0.0)
        win_pvalue = stats.binom_test(win_sig_snps,
                                      win_snps,
                                      exp_prob,
                                      alternative="greater")
                                      
        if win_pvalue < threshold:
            n_sig_wins += 1
            right_boundary = max(df_window["pos"])
            if left_boundary is None:
                left_boundary = min(df_window["pos"])

    print(n_sig_wins, "of", n_windows, "were significant")

    return left_boundary, right_boundary

def plot_associations(plot_fl, snp_pvalues, boundaries=None, y_limit=None):
    log10pvalues = -np.log10(df["pvalue"])
    max_value = max(log10pvalues)                

    if boundaries != None:
        left_boundary, right_boundary = boundaries
        
        plt.plot([left_boundary, left_boundary],
                 [0, max_value],
                 "k-",
                 label="Boundary")

        plt.plot([right_boundary, right_boundary],
                 [0, max_value],
                 "k-")

        plt.legend()

    fig = plt.gcf()
    fig.set_dpi(200)

    df_insign = df[df["is_significant"] == 0]
    if len(df_insign) != 0:
        log10pvalues = -np.log10(df_insign["pvalue"])
        plt.scatter(df_insign["pos"],
                    log10pvalues,
                    marker=".")

    df_sig = df[df["is_significant"] == 1]
    if len(df_sig) != 0:
        log10pvalues = -np.log10(df_sig["pvalue"])
        plt.scatter(df_sig["pos"],
                    log10pvalues,
                    marker=".",
                    label="Significant")

    plt.xlabel("Position (bp)", fontsize=16)
    plt.ylabel("SNP p-value (-log10)", fontsize=16)

    if y_limit:
        plt.ylim([0, y_limit])
    else:
        plt.ylim([0.0, max_value])

    plt.savefig(plot_fl)

def run_association_tests(variants, pc_coordinates, components):
    for variant_label, string_features in variants:
        for component in components:
            coords = pc_coordinates[:, component - 1]
            feature_to_coords = defaultdict(list)
            for i, (sample_name, feature) in enumerate(string_features):
                if feature != None:
                    feature_to_coords[feature].append(coords[i])

            if len(feature_to_coords) < 2:
                pvalue = 1.0
            else:
                _, pvalue = stats.f_oneway(*feature_to_coords.values())
            
                if np.isnan(pvalue) or np.isinf(pvalue):
                    pvalue = 1.0

            yield component, variant_label, pvalue

def write_test_results(flname, test_stream):    
    with open(flname, "w") as fl:
        next_output = 1

        headers = ["component", "chrom", "pos", "pvalue"]
        fl.write("\t".join(headers))
        fl.write("\n")

        for i, (compon, (pos_label), pvalue) in enumerate(test_stream):
            chrom, pos = pos_label
            if i == next_output:
                print(i, "Component", compon, "Position", pos_label, "has p-value", pvalue)
                next_output *= 2

            fl.write("\t".join([str(compon), chrom, str(pos), "%.2E" % pvalue]))
            fl.write("\n")
    
def parseargs():
    parser = argparse.ArgumentParser()

    subparsers = parser.add_subparsers(dest="mode")

    plot_parser = subparsers.add_parser("plot",
                                        help="Create Manhattan plot")
    
    plot_parser.add_argument("--input-tsv",
                             required=True,
                             type=str)

    plot_parser.add_argument("--plot-fl",
                             required=True,
                             type=str)

    plot_parser.add_argument("--component",
                             required=True,
                             type=int)

    plot_parser.add_argument("--chromosome",
                             required=True,
                             type=str)
    
    plot_parser.add_argument("--y-limit",
                             type=float)

    plot_parser.add_argument("--n-windows",
                             type=int,
                             default=10000)

    boundary_parser = subparsers.add_parser("detect-boundaries",
                                            help="Detect inversion boundaries")

    boundary_parser.add_argument("--input-tsv",
                                 required=True,
                                 type=str)

    boundary_parser.add_argument("--component",
                                 required=True,
                                 type=int)

    boundary_parser.add_argument("--chromosome",
                                 required=True,
                                 type=str)
    
    boundary_parser.add_argument("--n-windows",
                                 type=int,
                                 default=10000)

    association_parser = subparsers.add_parser("association-tests",
                                               help="Run PCA association tests for plotting and boundary detection")

    association_parser.add_argument("--workdir",
                                    type=str,
                                    help="Work directory",
                                    required=True)

    format_group = association_parser.add_mutually_exclusive_group(required=True)
    format_group.add_argument("--vcf", type=str, help="VCF file to import")
    format_group.add_argument("--vcf-gz", type=str, help="Gzipped VCF file to import")

    association_parser.add_argument("--allele-min-freq-threshold",
                                    type=float,
                                    help="Minimum allele frequency allowed",
                                    default=0.000001)

    association_parser.add_argument("--output-tsv",
                                    type=str,
                                    help="Output file",
                                    required=True)

    association_parser.add_argument("--components",
                                    type=int,
                                    nargs="+")
    
    return parser.parse_args()

if __name__ == "__main__":
    args = parseargs()

    if args.mode == "plot":
        df = read_snp_table(args.input_tsv,
                            args.component,
                            args.chromosome)
    
        df = mark_significant_snps(df)

        boundaries = None
        if args.n_windows != -1:
            boundaries = find_inversion_boundaries(df,
                                                   args.n_windows)
            print("Left boundary: {}".format(boundaries[0]))
            print("Right boundary: {}".format(boundaries[1]))

        plot_associations(args.plot_fl,
                          df,
                          boundaries=boundaries,
                          y_limit = args.y_limit)

    elif args.mode == "detect-boundaries":
        df = read_snp_table(args.input_tsv,
                            args.component,
                            args.chromosome)
    
        df = mark_significant_snps(df)

        left_boundary, right_boundary = find_inversion_boundaries(df,
                                                                  args.n_windows)

        print("Left boundary: {}".format(left_boundary))
        print("Right boundary: {}".format(right_boundary))

    elif args.mode == "association-tests":
        if not os.path.exists(args.workdir):
            print("Work directory '%s' does not exist." % args.workdir)
            sys.exit(1)

        project_summary = deserialize(os.path.join(args.workdir,
                                                   PROJECT_SUMMARY_FLNAME))
        sample_names = project_summary.sample_names

        model_fl = os.path.join(args.workdir,
                                "models",
                                MODEL_FLNAME)
        model = joblib.load(model_fl)
        projections = model[PROJECTION_KEY]

        if args.vcf is not None:
            flname = args.vcf
            gzipped = False
        else:
            flname = args.vcf_gz
            gzipped = True
    
        # the VCF streamer should return the
        # variants in the order of the given
        # kept_individuals parameter
        stream = VCFStreamer(flname,
                             gzipped,
                             kept_individuals = sample_names)

        filtered_variants = filter_invariants(args.allele_min_freq_threshold,
                                              stream)

        string_features = FeatureStringsExtractor(filtered_variants)

        test_stream = run_association_tests(string_features,
                                            projections,
                                            args.components)

        write_test_results(args.output_tsv,
                           test_stream)

    else:
        print("Unknown mode '{}'".format(args.mode))
        sys.exit(1)

        


