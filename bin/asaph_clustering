#!/usr/bin/env python3
"""
Copyright 2019 Ronald J. Nowling

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
"""


import argparse
from collections import defaultdict
import os
import sys
import warnings

import numpy as np

from sklearn.cluster import k_means
from sklearn.cluster import dbscan

from scipy.stats import chi2_contingency

from sklearn.linear_model import SGDClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import LabelEncoder

def read_pca_coordinates(flname):
    sample_coordinates = []
    sample_names = []
    with open(flname) as fl:
        # skip header
        next(fl)
        for ln in fl:
            cols = ln.split("\t")

            sample_name = cols[0]
            coordinates = list(map(float, cols[1:]))
            
            sample_names.append(sample_name)
            sample_coordinates.append(coordinates)

    return sample_names, np.array(sample_coordinates)

def read_label_names(flname):
    sample_indices = dict()

    with open(flname) as fl:
        for label_idx, ln in enumerate(fl):
            cols = ln.strip().split(",")

            label = cols[0]

            for sample_name in cols[1:]:
                sample_indices[sample_name] = label

    return sample_indices

def test_clusters(cluster_labels_fl, other_labels_fl):
    cluster_labels = read_label_names(cluster_labels_fl)
    other_labels = read_label_names(other_labels_fl)

    common_names = set(cluster_labels.keys()) & set(other_labels.keys())

    print(len(cluster_labels), len(other_labels), len(common_names))
    
    cluster_labels = { name : label for name, label in cluster_labels.items() if name in common_names }
    other_labels = { name : label for name, label in other_labels.items() if name in common_names }
    
    cluster_label_indices = { label : idx for idx, label in enumerate(set(cluster_labels.values())) }
    other_label_indices = { label : idx for idx, label in enumerate(set(other_labels.values())) }
    
    table = np.zeros((len(cluster_label_indices),
                      len(other_label_indices)))

    for sample_name in common_names:
        row = cluster_label_indices[cluster_labels[sample_name]]
        col = other_label_indices[other_labels[sample_name]]
        table[row, col] += 1
    
    _, pvalue, _, expected = chi2_contingency(table)

    print(table)
    print()
    print(expected)
    print()
    print("Chi2 p-value:", pvalue)
    print()
    
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")

        feature_encoder = OneHotEncoder(sparse=False)
        cluster_features = np.array(list(cluster_labels.values())).reshape(-1, 1)
        features = feature_encoder.fit_transform(cluster_features)

        label_encoder = LabelEncoder()
        sample_labels = label_encoder.fit_transform(list(other_labels.values()))
    
        lr = SGDClassifier(loss="log", penalty="l2", max_iter=1000, tol=1e-4)
        lr.fit(features, sample_labels)
        pred_labels = lr.predict(features)
        acc = accuracy_score(sample_labels, pred_labels)
        bal_acc = balanced_accuracy_score(sample_labels, pred_labels)

        print(pred_labels)
        print()
        print(sample_labels)

        print("Classifier accuracy:", acc)
        print("Balanced accuracy:", bal_acc)

def cluster_samples_kmeans(coordinates_fl, components, n_clusters, output_fl):
    if not os.path.exists(coordinates_fl):
        print("Coordinates file path is invalid")
        sys.exit(1)

    sample_names, coordinates = read_pca_coordinates(coordinates_fl)
    
    components = list(map(lambda idx: idx - 1, components))
    
    selected = coordinates[:, components]

    _, cluster_idx, inertia = k_means(selected,
                                      n_clusters)

    # group samples by cluster
    populations = defaultdict(set)
    for i, sample_name in enumerate(sample_names):
        cluster_assignment = cluster_idx[i]
        populations[cluster_assignment].add(sample_name)

    with open(output_fl, "w") as fl:
        for pop_name, samples in populations.items():
            fl.write(str(pop_name))
            for name in samples:
                fl.write(",")
                fl.write(name)
            fl.write("\n")        

def cluster_samples_dbscan(coordinates_fl, components, epsilon, min_samples, output_fl):
    if not os.path.exists(coordinates_fl):
        print("Coordinates file path is invalid")
        sys.exit(1)

    sample_names, coordinates = read_pca_coordinates(coordinates_fl)
    
    components = list(map(lambda idx: idx - 1, components))
    
    selected = coordinates[:, components]

    _, cluster_idx = dbscan(selected, eps=epsilon, min_samples=min_samples)

    # group samples by cluster
    populations = defaultdict(set)
    outliers = []
    for i, sample_name in enumerate(sample_names):
        # ignore outliers
        if cluster_idx[i] != -1:
            cluster_assignment = cluster_idx[i]
            populations[cluster_assignment].add(sample_name)
        else:
            outliers.append(sample_name)

    if len(outliers) > 0:
        print("The following samples were marked as outliers:", ",".join(outliers))

    if len(populations) == 0:
        warnings.warn("All samples were marked as outliers!", UserWarning)

    with open(output_fl, "w") as fl:
        for pop_name, samples in populations.items():
            fl.write(str(pop_name))
            for name in samples:
                fl.write(",")
                fl.write(name)
            fl.write("\n")

def parseargs():
    parser = argparse.ArgumentParser()

    subparsers = parser.add_subparsers(dest="mode",
                                       required=True)

    test_clusters_parser = subparsers.add_parser("test-clusters",
                                                   help="Association tests between clusters and known labels")
    
    test_clusters_parser.add_argument("--cluster-labels-fl",
                                      type=str,
                                      required=True)

    test_clusters_parser.add_argument("--other-labels-fl",
                                       type=str,
                                       required=True)

    kmeans_parser = subparsers.add_parser("cluster-samples-kmeans",
                                          help="Cluster samples with k-means")

    kmeans_parser.add_argument("--coordinates",
                               type=str,
                               required=True)
    
    kmeans_parser.add_argument("--components",
                               type=int,
                               nargs="+",
                               required=True,
                               help="Components to use in projection")

    kmeans_parser.add_argument("--n-clusters",
                               type=int,
                               required=True,
                               help="Number of clusters")

    kmeans_parser.add_argument("--output-labels-fl",
                               type=str,
                               required=True,
                               help="Labels file to output")

    dbscan_parser = subparsers.add_parser("cluster-samples-dbscan",
                                          help="Cluster samples with dbscan")

    dbscan_parser.add_argument("--coordinates",
                               type=str,
                               required=True)
    
    dbscan_parser.add_argument("--components",
                               type=int,
                               nargs="+",
                               required=True,
                               help="Components to use in projection")

    dbscan_parser.add_argument("--epsilon",
                               type=float,
                               default=0.5,
                               help="Maximum distance between two points in the same neighborhood")

    dbscan_parser.add_argument("--min-samples",
                               type=int,
                               default=5,
                               help="Minimum samples per cluster core")
    
    dbscan_parser.add_argument("--output-labels-fl",
                               type=str,
                               required=True,
                               help="Labels file to output")
    
    return parser.parse_args()

if __name__ == "__main__":
    args = parseargs()

    if args.mode == "test-clusters":
        test_clusters(args.cluster_labels_fl,
                      args.other_labels_fl)

    elif args.mode == "cluster-samples-kmeans":
        cluster_samples_kmeans(args.coordinates,
                               args.components,
                               args.n_clusters,
                               args.output_labels_fl)

    elif args.mode == "cluster-samples-dbscan":
        cluster_samples_dbscan(args.coordinates,
                               args.components,
                               args.epsilon,
                               args.min_samples,
                               args.output_labels_fl)

    else:
        print("Unknown mode '%s'" % args.mode)
        sys.exit(1)
