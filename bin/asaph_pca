#!/usr/bin/env python3

"""
Copyright 2015 Ronald J. Nowling

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
"""

import argparse
import os
import sys

import joblib
import matplotlib
matplotlib.use("PDF")
import matplotlib.pyplot as plt
import numpy as np
from sklearn.decomposition import PCA
from sklearn.random_projection import johnson_lindenstrauss_min_dim as jl_min_dim

from asaph.feature_matrix_construction import construct_feature_matrix
from asaph.feature_matrix_construction import COUNTS_FEATURE_TYPE
from asaph.feature_matrix_construction import CATEGORIES_FEATURE_TYPE
from asaph.feature_matrix_construction import HASHED_FEATURE_TYPE
from asaph.models import ProjectSummary
from asaph.newioutils import deserialize
from asaph.newioutils import FEATURES_FLNAME
from asaph.newioutils import MODEL_FLNAME
from asaph.newioutils import MODEL_KEY
from asaph.newioutils import PROJECT_SUMMARY_FLNAME
from asaph.newioutils import PROJECTION_KEY
from asaph.newioutils import read_sample_names
from asaph.newioutils import SAMPLE_LABELS_FLNAME
from asaph.newioutils import serialize
from asaph.vcf import stream_vcf_variants

def calculate_dimensions(n_samples, args):
    if args.num_dimensions is None and args.min_inversion_fraction is None:
        n_dim = jl_min_dim(n_samples, eps=0.1)
    elif args.min_inversion_fraction is not None:
        if not (0.0 < args.min_inversion_fraction < 1.0):
            raise Exception("Minimum inversion fraction must be a number between 0 and 1 (exclusive).")
        n_dim = jl_min_dim(n_samples, eps=args.min_inversion_fraction)
    elif args.num_dimensions is not None:
        n_dim = args.num_dimensions

    return n_dim

def import_vcf(args):
    if not os.path.exists(args.workdir):
        os.makedirs(args.workdir)

    if args.vcf is not None:
        flname = args.vcf
        gzipped = False
    else:
        flname = args.vcf_gz
        gzipped = True

    variant_stream, individual_names = stream_vcf_variants(flname,
                                                           gzipped,
                                                           args.allele_min_freq_threshold)

    n_samples = len(individual_names)
    n_dim = calculate_dimensions(n_samples, args)
    
    feature_matrix = construct_feature_matrix(variant_stream,
                                              n_samples,
                                              args.feature_type,
                                              args.subsampling_method,
                                              args.chunk_size,
                                              n_dim,
                                              n_inner_dim=args.inner_dim)

    print(feature_matrix.shape[0], "individuals")
    print(feature_matrix.shape[1], "features")

    project_summary = ProjectSummary(original_positions = None,
                                     filtered_positions = None,
                                     n_features = feature_matrix.shape[1],
                                     n_samples = feature_matrix.shape[0],
                                     feature_type = args.feature_type,
                                     subsampling_method = args.subsampling_method,
                                     sample_names = individual_names)

    serialize(os.path.join(args.workdir, SAMPLE_LABELS_FLNAME), individual_names)
    serialize(os.path.join(args.workdir, PROJECT_SUMMARY_FLNAME), project_summary)
    serialize(os.path.join(args.workdir, FEATURES_FLNAME), feature_matrix)

    print("Variants imported")

    return feature_matrix

def train_pca(feature_matrix, args):
    models_dir = os.path.join(args.workdir, "models")
    if not os.path.exists(models_dir):
        os.makedirs(models_dir)
    
    print("Training PCA model with %s components" % args.n_components)
    pca = PCA(n_components = args.n_components,
              whiten = True)

    projections = pca.fit_transform(feature_matrix)

    model = { MODEL_KEY : pca,
              PROJECTION_KEY : projections}

    model_fl = os.path.join(models_dir,
                            MODEL_FLNAME)
    joblib.dump(model,
                model_fl)

def explained_variance_analysis(args):
    workdir = args.workdir

    figures_dir = os.path.join(workdir, "figures")
    if not os.path.exists(figures_dir):
        os.makedirs(figures_dir)

    model_fl = os.path.join(workdir,
                            "models",
                            MODEL_FLNAME)

    model = joblib.load(model_fl)

    explained_variance_ratios = model[MODEL_KEY].explained_variance_ratio_

    fig_flname = os.path.join(figures_dir,
                              "pca_explained_variance_ratios.png")

    print(explained_variance_ratios)

    plt.clf()
    plt.grid(True)
    fig = plt.gcf()
    fig.set_dpi(150)
    plt.plot(range(1, len(explained_variance_ratios) + 1),
             explained_variance_ratios, "m.-")
    plt.xlabel("Principal Component", fontsize=16)
    plt.ylabel("Explained Variance Ratio", fontsize=16)
    plt.ylim([0., 1.])
    plt.savefig(fig_flname)

def output_coordinates(args):
    workdir = args.workdir

    project_summary = deserialize(os.path.join(workdir,
                                               PROJECT_SUMMARY_FLNAME))

    model_fl = os.path.join(workdir,
                            "models",
                            MODEL_FLNAME)
    model = joblib.load(model_fl)    
    projected = model[PROJECTION_KEY]
    selected = projected[:, list(map(lambda idx: idx - 1, args.selected_components))]

    sample_names = read_sample_names(workdir)

    with open(args.output_fl, "w") as fl:
        headers = ["sample"]
        headers.extend(map(str, args.selected_components))
        fl.write("\t".join(headers))
        fl.write("\n")

        for i, sample_name in enumerate(sample_names):
            line = [sample_name]
            line.extend(map(str, selected[i, :]))
            fl.write("\t".join(line))
            fl.write("\n")

def parseargs():
    parser = argparse.ArgumentParser(description="Asaph")

    parser.add_argument("--workdir",
                        type=str,
                        required=True,
                        help="Work directory")

    subparsers = parser.add_subparsers(dest="mode", required=True)

    train_parser = subparsers.add_parser("train",
                                         help="Train dimensionality reduction model")
    
    train_parser.add_argument("--n-components",
                              type=int,
                              default=10,
                              help="Number of PCs to compute")

    train_parser.add_argument("--feature-type",
                              type=str,
                              default="hashed",
                              choices=["counts",
                                       "categories",
                                       "hashed"])

    train_parser.add_argument("--subsampling-method",
                              type=str,
                              default=None,
                              choices=["random-projection",
                                       "reservoir"])

    train_parser.add_argument("--chunk-size",
                              type=int,
                              default=10000)

    dimensions_group = train_parser.add_mutually_exclusive_group()
    dimensions_group.add_argument("--num-dimensions",
                                  type=int,
                                  default=None,
                                  help="Set number of dimensions to use for reduced space." )

    dimensions_group.add_argument("--min-inversion-fraction",
                                  type=float,
                                  help="Use minimum inversion size (in terms of fraction of SNPs) to estimate number of dimensions needed.")

    train_parser.add_argument("--inner-dim",
                              type=int,
                              default=2**20,
                              help="Number of hashed features to use as an inner dimension with random projection.")
    
    format_group = train_parser.add_mutually_exclusive_group(required=True)
    format_group.add_argument("--vcf", type=str, help="VCF file to import")
    format_group.add_argument("--vcf-gz", type=str, help="Gzipped VCF file to import")

    train_parser.add_argument("--selected-samples",
                              type=str,
                              help="Use only these samples")

    train_parser.add_argument("--allele-min-freq-threshold",
                              type=float,
                              help="Minimum allele frequency allowed",
                              default=0.000001)

    eva_parser = subparsers.add_parser("explained-variance-analysis",
                                       help="Compute explained variances of PCs")

    output_parser = subparsers.add_parser("output-coordinates",
                                      help="Output PC projected coordinates")
        
    output_parser.add_argument("--selected-components",
                               type=int,
                               nargs="+",
                               help="Components to output")

    output_parser.add_argument("--output-fl",
                               type=str,
                               required=True,
                               help="Output file")


    return parser.parse_args()

if __name__ == "__main__":
    args = parseargs()

    if args.mode == "train":
       features = import_vcf(args)
       train_pca(features, args)
    elif args.mode == "explained-variance-analysis":
        explained_variance_analysis(args)
    elif args.mode == "output-coordinates":
        output_coordinates(args)
    else:
        print("Unknown mode '%s'" % args.mode)
        sys.exit(1)
